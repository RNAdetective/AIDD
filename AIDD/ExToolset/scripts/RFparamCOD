> data <- read.csv("/media/sf_AIDD/all_excitomefreq/MDDfreqall2.csv")
> data$COD = factor(data$COD)
> seed <- 7
> metric <- "Accuracy"
> customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
> customRF$parameters <- data.frame(parameter = c("nodesize","mtry"), class = rep("numeric", 2), label = c("nodesize","mtry"))
> customRF$grid <- function(x, y, len = NULL, search = "grid") {}
> customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
+   randomForest(x, y, nodesize = param$nodesize, mtry=param$mtry, ...)
+ }
> customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata)
> customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata, type = "prob")
> customRF$sort <- function(x) x[order(x[,1]),]
> customRF$levels <- function(x) x$classes
> control <- trainControl(method="repeatedcv", number=10, repeats=3)
> tunegrid <- expand.grid(.nodesize=c(1:15),.mtry=c(5,10,20,30,40,50,60,70,80,90,100))
> set.seed(seed)
> custom <- train(COD~., data=data, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control,na.action=na.roughfix)
> summary(custom)
                Length Class      Mode     
call               5   -none-     call     
type               1   -none-     character
predicted        303   factor     numeric  
err.rate        1500   -none-     numeric  
confusion          6   -none-     numeric  
votes            606   matrix     numeric  
oob.times        303   -none-     numeric  
classes            2   -none-     character
importance       144   -none-     numeric  
importanceSD       0   -none-     NULL     
localImportance    0   -none-     NULL     
proximity          0   -none-     NULL     
ntree              1   -none-     numeric  
mtry               1   -none-     numeric  
forest            14   -none-     list     
y                303   factor     numeric  
test               0   -none-     NULL     
inbag              0   -none-     NULL     
xNames           144   -none-     character
problemType        1   -none-     character
tuneValue          2   data.frame list     
obsLevels          2   -none-     character
param              0   -none-     list     
> custom
303 samples
139 predictors
  2 classes: 'Natural', 'Suicide' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 272, 272, 272, 273, 272, 274, ... 
Resampling results across tuning parameters:

  nodesize  mtry  Accuracy   Kappa    
   1          5   0.8330021  0.4934262
   1         10   0.8340749  0.4949016
   1         20   0.8505673  0.5436298
   1         30   0.8549042  0.5551126
   1         40   0.8560487  0.5581467
   1         50   0.8614992  0.5797924
   1         60   0.8659844  0.5967330
   1         70   0.8748041  0.6279670
   1         80   0.8768805  0.6317960
   1         90   0.8780299  0.6370379
   1        100   0.8813299  0.6473589
   2          5   0.8263663  0.4795646
   2         10   0.8330379  0.4953166
   2         20   0.8440415  0.5237017
   2         30   0.8515684  0.5472805
   2         40   0.8539365  0.5548624
   2         50   0.8604215  0.5772033
   2         60   0.8669831  0.5962194
   2         70   0.8735447  0.6250169
   2         80   0.8789593  0.6401805
   2         90   0.8780299  0.6354595
   2        100   0.8823285  0.6535057
   3          5   0.8253269  0.4718264
   3         10   0.8264405  0.4777699
   3         20   0.8419318  0.5179965
   3         30   0.8594253  0.5718505
   3         40   0.8582375  0.5656812
   3         50   0.8648325  0.5902194
   3         60   0.8680225  0.6051059
   3         70   0.8769546  0.6363663
   3         80   0.8791793  0.6415825
   3         90   0.8769213  0.6351596
   3        100   0.8834779  0.6538759
   4          5   0.8296280  0.4857758
   4         10   0.8264022  0.4764068
   4         20   0.8473056  0.5332819
   4         30   0.8614658  0.5758533
   4         40   0.8626103  0.5794885
   4         50   0.8581251  0.5710979
   4         60   0.8659844  0.6005717
   4         70   0.8767705  0.6341469
   4         80   0.8791052  0.6413901
   4         90   0.8790693  0.6400138
   4        100   0.8846632  0.6602623
   5          5   0.8273674  0.4834402
   5         10   0.8285910  0.4818825
   5         20   0.8505315  0.5396451
   5         30   0.8604264  0.5723737
   5         40   0.8626462  0.5835351
   5         50   0.8636089  0.5897406
   5         60   0.8692819  0.6068219
   5         70   0.8802546  0.6402804
   5         80   0.8845890  0.6529570
   5         90   0.8801829  0.6429887
   5        100   0.8835138  0.6527096
   6          5   0.8219194  0.4685892
   6         10   0.8285169  0.4855924
   6         20   0.8493845  0.5411894
   6         30   0.8670214  0.5911175
   6         40   0.8637956  0.5849509
   6         50   0.8692411  0.6047957
   6         60   0.8746224  0.6297839
   6         70   0.8758794  0.6301112
   6         80   0.8758077  0.6321649
   6         90   0.8791052  0.6458839
   6        100   0.8846966  0.6621251
   7          5   0.8241058  0.4705942
   7         10   0.8307774  0.4902378
   7         20   0.8472673  0.5377400
   7         30   0.8637597  0.5859857
   7         40   0.8603881  0.5764426
   7         50   0.8692794  0.6023276
   7         60   0.8672031  0.6023024
   7         70   0.8703238  0.6162156
   7         80   0.8802188  0.6454795
   7         90   0.8802521  0.6474427
   7        100   0.8789952  0.6488486
   8          5   0.8253294  0.4764893
   8         10   0.8275158  0.4816163
   8         20   0.8483784  0.5383862
   8         30   0.8549401  0.5595440
   8         40   0.8614967  0.5804919
   8         50   0.8646892  0.5956558
   8         60   0.8725844  0.6195941
   8         70   0.8767346  0.6336978
   8         80   0.8789927  0.6461154
   8         90   0.8824410  0.6537043
   8        100   0.8845174  0.6599169
   9          5   0.8241058  0.4752746
   9         10   0.8297021  0.4868459
   9         20   0.8462687  0.5364094
   9         30   0.8571623  0.5636398
   9         40   0.8626103  0.5806549
   9         50   0.8649808  0.5948466
   9         60   0.8726202  0.6190700
   9         70   0.8736571  0.6281589
   9         80   0.8824027  0.6580626
   9         90   0.8845890  0.6621758
   9        100   0.8835163  0.6634160
  10          5   0.8241058  0.4747620
  10         10   0.8275516  0.4778799
  10         20   0.8516426  0.5465404
  10         30   0.8635756  0.5833424
  10         40   0.8670597  0.5974629
  10         50   0.8636856  0.5893733
  10         60   0.8713991  0.6205762
  10         70   0.8779174  0.6395045
  10         80   0.8780274  0.6439857
  10         90   0.8801780  0.6522527
  10        100   0.8834421  0.6616568
  11          5   0.8262563  0.4810697
  11         10   0.8274774  0.4776092
  11         20   0.8527920  0.5580675
  11         30   0.8570523  0.5667565
  11         40   0.8658720  0.5956011
  11         50   0.8604622  0.5810421
  11         60   0.8700989  0.6172823
  11         70   0.8713991  0.6261426
  11         80   0.8768063  0.6392407
  11         90   0.8888901  0.6738796
  11        100   0.8856643  0.6696630
  12          5   0.8229947  0.4695027
  12         10   0.8306674  0.4900901
  12         20   0.8517526  0.5449729
  12         30   0.8604598  0.5749528
  12         40   0.8603856  0.5748222
  12         50   0.8647608  0.5934988
  12         60   0.8681374  0.6114197
  12         70   0.8768830  0.6389261
  12         80   0.8735088  0.6313561
  12         90   0.8845915  0.6628233
  12        100   0.8834779  0.6622680
  13          5   0.8251811  0.4790970
  13         10   0.8297405  0.4852060
  13         20   0.8473056  0.5340645
  13         30   0.8647250  0.5893691
  13         40   0.8648325  0.5886140
  13         50   0.8637622  0.5946046
  13         60   0.8769930  0.6345821
  13         70   0.8768446  0.6371980
  13         80   0.8791460  0.6469446
  13         90   0.8822568  0.6549860
  13        100   0.8855951  0.6655916
  14          5   0.8241058  0.4748832
  14         10   0.8296280  0.4881392
  14         20   0.8526820  0.5490479
  14         30   0.8603522  0.5717460
  14         40   0.8636831  0.5834677
  14         50   0.8691336  0.6061099
  14         60   0.8725844  0.6207148
  14         70   0.8790335  0.6449444
  14         80   0.8779199  0.6418121
  14         90   0.8812557  0.6505797
  14        100   0.8890001  0.6716920
  15          5   0.8241058  0.4747620
  15         10   0.8297021  0.4860918
  15         20   0.8484551  0.5387359
  15         30   0.8616092  0.5744213
  15         40   0.8603498  0.5762107
  15         50   0.8649067  0.5925319
  15         60   0.8692844  0.6148046
  15         70   0.8724385  0.6255772
  15         80   0.8824051  0.6555217
  15         90   0.8911148  0.6822532
  15        100   0.8800729  0.6529228

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were nodesize = 15 and mtry = 90.
> file_name <- "/media/sf_AIDD/rfparamNodeMtry.tiff"
> tiff(file_name, units="in", width=10, height=10, res=600)
> plot(custom)
> dev.off()
null device 
          1 
> ##3
> ##3
> data <- read.csv("/media/sf_AIDD/all_excitomefreq/MDDfreqall2.csv")
> data$COD = factor(data$COD)
> seed <- 7
> metric <- "Accuracy"
> customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
> customRF$parameters <- data.frame(parameter = c("nodesize","ntree"), class = rep("numeric", 2), label = c("nodesize","ntree"))
> customRF$grid <- function(x, y, len = NULL, search = "grid") {}
> customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
+   randomForest(x, y, nodesize = param$nodesize, ntree=param$ntree, ...)
+ }
> customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata)
> customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata, type = "prob")
> customRF$sort <- function(x) x[order(x[,1]),]
> customRF$levels <- function(x) x$classes
> 
> control <- trainControl(method="repeatedcv", number=10, repeats=3)
> tunegrid <- expand.grid(.nodesize=c(1:15),.ntree=c(50,100,300,500,1000,1500,3000,5000,10000))
> set.seed(seed)
> custom <- train(COD~., data=data, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control,na.action=na.roughfix)
> summary(custom)
                Length Class      Mode     
call              5    -none-     call     
type              1    -none-     character
predicted       303    factor     numeric  
err.rate        150    -none-     numeric  
confusion         6    -none-     numeric  
votes           606    matrix     numeric  
oob.times       303    -none-     numeric  
classes           2    -none-     character
importance      144    -none-     numeric  
importanceSD      0    -none-     NULL     
localImportance   0    -none-     NULL     
proximity         0    -none-     NULL     
ntree             1    -none-     numeric  
mtry              1    -none-     numeric  
forest           14    -none-     list     
y               303    factor     numeric  
test              0    -none-     NULL     
inbag             0    -none-     NULL     
xNames          144    -none-     character
problemType       1    -none-     character
tuneValue         2    data.frame list     
obsLevels         2    -none-     character
param             0    -none-     list     
> custom
303 samples
139 predictors
  2 classes: 'Natural', 'Suicide' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 272, 272, 272, 273, 272, 274, ... 
Resampling results across tuning parameters:

  nodesize  ntree  Accuracy   Kappa    
   1           50  0.8394512  0.5140862
   1          100  0.8395637  0.5097777
   1          300  0.8330355  0.4876834
   1          500  0.8341132  0.4936402
   1         1000  0.8341132  0.4936769
   1         1500  0.8351168  0.5015130
   1         3000  0.8319627  0.4881654
   1         5000  0.8330021  0.4935241
   1        10000  0.8330404  0.4936205
   2           50  0.8351502  0.5007185
   2          100  0.8386343  0.5063049
   2          300  0.8352243  0.4960198
   2          500  0.8384884  0.5102209
   2         1000  0.8285527  0.4812186
   2         1500  0.8318885  0.4882539
   2         3000  0.8340391  0.4950191
   2         5000  0.8329279  0.4928223
   2        10000  0.8330021  0.4930160
   3           50  0.8395612  0.5037569
   3          100  0.8373749  0.5056172
   3          300  0.8373365  0.5082899
   3          500  0.8363021  0.5047068
   3         1000  0.8352985  0.4993551
   3         1500  0.8340749  0.4968836
   3         3000  0.8352985  0.4979126
   3         5000  0.8319627  0.4893907
   3        10000  0.8341132  0.4968567
   4           50  0.8440032  0.5221162
   4          100  0.8351143  0.4998928
   4          300  0.8372649  0.5077862
   4          500  0.8363737  0.5058093
   4         1000  0.8341132  0.4968567
   4         1500  0.8308899  0.4871190
   4         3000  0.8341515  0.4971293
   4         5000  0.8330379  0.4935247
   4        10000  0.8330021  0.4930160
   5           50  0.8364479  0.5089009
   5          100  0.8329996  0.4932822
   5          300  0.8373749  0.5088271
   5          500  0.8374849  0.5066812
   5         1000  0.8341132  0.4953540
   5         1500  0.8374490  0.5062923
   5         3000  0.8318910  0.4906455
   5         5000  0.8330021  0.4927161
   5        10000  0.8341132  0.4986409
   6           50  0.8341874  0.4945219
   6          100  0.8352985  0.5022721
   6          300  0.8329638  0.4925557
   6          500  0.8319268  0.4924530
   6         1000  0.8341515  0.4953476
   6         1500  0.8320010  0.4912737
   6         3000  0.8330404  0.4950176
   6         5000  0.8341874  0.4974617
   6        10000  0.8352626  0.4994999
   7           50  0.8494920  0.5400461
   7          100  0.8396737  0.5123735
   7          300  0.8275899  0.4815272
   7          500  0.8286627  0.4801133
   7         1000  0.8373007  0.5084390
   7         1500  0.8308516  0.4902492
   7         3000  0.8308516  0.4902492
   7         5000  0.8341132  0.4983409
   7        10000  0.8330021  0.4948003
   8           50  0.8305933  0.4877746
   8          100  0.8338932  0.4991098
   8          300  0.8385601  0.5131444
   8          500  0.8318502  0.4896428
   8         1000  0.8340391  0.4996902
   8         1500  0.8352268  0.4994816
   8         3000  0.8330021  0.4984803
   8         5000  0.8297405  0.4879346
   8        10000  0.8319268  0.4938677
   9           50  0.8296663  0.4852906
   9          100  0.8362613  0.5017576
   9          300  0.8286269  0.4797692
   9          500  0.8319268  0.4937556
   9         1000  0.8285169  0.4827049
   9         1500  0.8307416  0.4920081
   9         3000  0.8296663  0.4895487
   9         5000  0.8319268  0.4939231
   9        10000  0.8297405  0.4879346
  10           50  0.8351143  0.4967835
  10          100  0.8297021  0.4798555
  10          300  0.8351502  0.5007502
  10          500  0.8373749  0.5061972
  10         1000  0.8384501  0.5127329
  10         1500  0.8352243  0.5035462
  10         3000  0.8297021  0.4888320
  10         5000  0.8307416  0.4916965
  10        10000  0.8286269  0.4850097
  11           50  0.8295897  0.4868825
  11          100  0.8382660  0.5087700
  11          300  0.8307774  0.4876095
  11          500  0.8319627  0.4923148
  11         1000  0.8341132  0.4996085
  11         1500  0.8318527  0.4940572
  11         3000  0.8297405  0.4886695
  11         5000  0.8308157  0.4908173
  11        10000  0.8296663  0.4878741
  12           50  0.8340724  0.4994199
  12          100  0.8307774  0.4904400
  12          300  0.8340032  0.4951293
  12          500  0.8308874  0.4901807
  12         1000  0.8286652  0.4841122
  12         1500  0.8318910  0.4910298
  12         3000  0.8307774  0.4919192
  12         5000  0.8308157  0.4921919
  12        10000  0.8285910  0.4857263
  13           50  0.8330763  0.4934128
  13          100  0.8329663  0.4968160
  13          300  0.8319268  0.4928101
  13          500  0.8297380  0.4896988
  13         1000  0.8275158  0.4837536
  13         1500  0.8297405  0.4880579
  13         3000  0.8285910  0.4849914
  13         5000  0.8295921  0.4872277
  13        10000  0.8296663  0.4895487
  14           50  0.8351452  0.5013308
  14          100  0.8342207  0.4991932
  14          300  0.8362996  0.5070741
  14          500  0.8318168  0.4980733
  14         1000  0.8264405  0.4788847
  14         1500  0.8296663  0.4895487
  14         3000  0.8296663  0.4877230
  14         5000  0.8296663  0.4895487
  14        10000  0.8296663  0.4895487
  15           50  0.8276258  0.4759851
  15          100  0.8308516  0.4856387
  15          300  0.8274416  0.4774871
  15          500  0.8285169  0.4826704
  15         1000  0.8275158  0.4834419
  15         1500  0.8296663  0.4895487
  15         3000  0.8285910  0.4857263
  15         5000  0.8296663  0.4895487
  15        10000  0.8296663  0.4895487

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were nodesize = 7 and ntree = 50.
> file_name <- "/media/sf_AIDD/rfparamNodeNtree.tiff"
> tiff(file_name, units="in", width=10, height=10, res=600)
> plot(custom)
> dev.off()
null device 
          1 
> ##4
> data <- read.csv("/media/sf_AIDD/all_excitomefreq/MDDfreqall2.csv")
> data$COD = factor(data$COD)
> seed <- 7
> metric <- "Accuracy"
> customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
> customRF$parameters <- data.frame(parameter = c("ntree","mtry"), class = rep("numeric", 2), label = c("ntree","mtry"))
> customRF$grid <- function(x, y, len = NULL, search = "grid") {}
> customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
+   randomForest(x, y, ntree = param$ntree, mtry=param$mtry, ...)
+ }
> customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata)
> customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
+    predict(modelFit, newdata, type = "prob")
> customRF$sort <- function(x) x[order(x[,1]),]
> customRF$levels <- function(x) x$classes
> 
> control <- trainControl(method="repeatedcv", number=10, repeats=3)
> tunegrid <- expand.grid(.ntree=c(50,100,300,500,1000,1500,3000,5000,10000),.mtry=c(5,10,20,30,40,50,60,70,80))
> set.seed(seed)
> custom <- train(COD~., data=data, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control,na.action=na.roughfix)
> summary(custom)
                Length Class      Mode     
call               5   -none-     call     
type               1   -none-     character
predicted        303   factor     numeric  
err.rate        1500   -none-     numeric  
confusion          6   -none-     numeric  
votes            606   matrix     numeric  
oob.times        303   -none-     numeric  
classes            2   -none-     character
importance       144   -none-     numeric  
importanceSD       0   -none-     NULL     
localImportance    0   -none-     NULL     
proximity          0   -none-     NULL     
ntree              1   -none-     numeric  
mtry               1   -none-     numeric  
forest            14   -none-     list     
y                303   factor     numeric  
test               0   -none-     NULL     
inbag              0   -none-     NULL     
xNames           144   -none-     character
problemType        1   -none-     character
tuneValue          2   data.frame list     
obsLevels          2   -none-     character
param              0   -none-     list     
> custom
303 samples
139 predictors
  2 classes: 'Natural', 'Suicide' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 
Summary of sample sizes: 272, 272, 272, 273, 272, 274, ... 
Resampling results across tuning parameters:

  ntree  mtry  Accuracy   Kappa    
     50   5    0.8251094  0.4582180
     50  10    0.8353702  0.4993749
     50  20    0.8416018  0.5152176
     50  30    0.8418576  0.5274306
     50  40    0.8481251  0.5439840
     50  50    0.8692844  0.6162895
     50  60    0.8660561  0.6098613
     50  70    0.8744407  0.6302145
     50  80    0.8656878  0.6076256
    100   5    0.8187319  0.4441293
    100  10    0.8319627  0.4842294
    100  20    0.8504215  0.5399925
    100  30    0.8615017  0.5776719
    100  40    0.8635014  0.5834094
    100  50    0.8592387  0.5754118
    100  60    0.8669089  0.6027349
    100  70    0.8779558  0.6377663
    100  80    0.8802163  0.6469472
    300   5    0.8285910  0.4842796
    300  10    0.8341515  0.4974399
    300  20    0.8473056  0.5337850
    300  30    0.8504548  0.5415621
    300  40    0.8559745  0.5592408
    300  50    0.8669806  0.5937537
    300  60    0.8626103  0.5876722
    300  70    0.8714325  0.6158463
    300  80    0.8758052  0.6309930
    500   5    0.8296663  0.4828921
    500  10    0.8318910  0.4909773
    500  20    0.8462304  0.5297139
    500  30    0.8517167  0.5457747
    500  40    0.8593128  0.5696007
    500  50    0.8615375  0.5806320
    500  60    0.8626486  0.5824375
    500  70    0.8724694  0.6195905
    500  80    0.8813991  0.6489043
   1000   5    0.8252911  0.4733800
   1000  10    0.8318910  0.4902094
   1000  20    0.8506056  0.5437217
   1000  30    0.8615375  0.5783646
   1000  40    0.8592745  0.5720991
   1000  50    0.8593845  0.5686912
   1000  60    0.8682042  0.6045923
   1000  70    0.8748783  0.6253454
   1000  80    0.8736547  0.6242022
   1500   5    0.8274774  0.4798056
   1500  10    0.8308516  0.4890538
   1500  20    0.8494945  0.5358628
   1500  30    0.8560153  0.5612698
   1500  40    0.8583475  0.5679236
   1500  50    0.8626103  0.5827813
   1500  60    0.8692436  0.6064771
   1500  70    0.8748041  0.6270974
   1500  80    0.8812916  0.6432104
   3000   5    0.8274774  0.4783092
   3000  10    0.8297021  0.4805908
   3000  20    0.8494203  0.5369703
   3000  30    0.8571648  0.5652452
   3000  40    0.8603856  0.5738483
   3000  50    0.8593845  0.5742639
   3000  60    0.8615709  0.5857374
   3000  70    0.8769546  0.6341970
   3000  80    0.8779941  0.6335985
   5000   5    0.8251811  0.4747486
   5000  10    0.8308516  0.4832340
   5000  20    0.8495303  0.5399074
   5000  30    0.8571648  0.5636115
   5000  40    0.8581634  0.5666331
   5000  50    0.8615375  0.5801910
   5000  60    0.8670572  0.6025751
   5000  70    0.8725436  0.6201799
   5000  80    0.8791052  0.6373385
  10000   5    0.8252169  0.4752829
  10000  10    0.8297021  0.4805908
  10000  20    0.8516809  0.5458777
  10000  30    0.8538648  0.5561753
  10000  40    0.8549017  0.5560881
  10000  50    0.8594587  0.5723918
  10000  60    0.8649067  0.5951013
  10000  70    0.8747299  0.6278474
  10000  80    0.8791052  0.6376338

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were ntree = 500 and mtry = 80.
> file_name <- "/media/sf_AIDD/rfparamNtreeMtry.tiff"
> tiff(file_name, units="in", width=10, height=10, res=600)
> plot(custom)
> dev.off()
null device 
          1

